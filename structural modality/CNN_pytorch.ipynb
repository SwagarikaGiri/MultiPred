{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from random import randint\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import fbeta_score, precision_recall_fscore_support, multilabel_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.set_num_threads(5)\n",
    "\n",
    "''' \n",
    "    type_of_dataset:\n",
    "        a)1 --->>> 'bp'\n",
    "        b)2 --->>> 'cc'\n",
    "        c)3 --->>> 'mf'\n",
    "        \n",
    "    type_of_image:\n",
    "        a)None\n",
    "        b)charge\n",
    "        c)hydropathy\n",
    "        d)isoelectric\n",
    "'''\n",
    "\n",
    "type_of_image = 'None'\n",
    "type_of_dataset = '1'\n",
    "output_dim = 932\n",
    "weights_path = 'weights_{}_{}.pth'.format(type_of_dataset, type_of_image)\n",
    "if type_of_dataset == '1':\n",
    "    output_dim = 932\n",
    "    d = 'bp'\n",
    "if type_of_dataset == '2':\n",
    "    output_dim = 439\n",
    "    d = 'cc'\n",
    "if type_of_dataset == '3':\n",
    "    output_dim = 589\n",
    "    d = 'mf'\n",
    "\n",
    "train_dir = 'Data_preprocessing/Examples/{}/{}'.format(d, type_of_image)    #provide path for generated voxel datas\n",
    "labels_csv = '{}.csv'.format(d)                                             #provide the path for labels\n",
    "resnet_weights_path = 'Resnet50.pth'                                        #provide path for pretrained resnet50 weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 20\n",
    "PERCENTILE = 99.7\n",
    "LEARNING_RATE = 0.0001\n",
    "DISABLE_TQDM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(labels_csv)\n",
    "attribute_dict = dict(zip(df.accession_no,df.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transform.\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "class ImageData(data.Dataset):\n",
    "    def __init__(self,df,dirpath,transform,test = False):\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "        self.dirpath = dirpath\n",
    "        self.conv_to_tensor = transform\n",
    "        #image data \n",
    "        if not self.test:\n",
    "            self.image_arr = np.asarray(str(self.dirpath)+'/'+self.df.iloc[:, 0])\n",
    "        else:\n",
    "            self.image_arr = np.asarray(str(self.dirpath)+'/'+self.df.iloc[:, 0])\n",
    "        \n",
    "        #labels data\n",
    "        if not self.test:\n",
    "             self.label_df = self.df.iloc[:,1]\n",
    "        \n",
    "        # Calculate length of df\n",
    "        self.data_len = len(self.df.index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_arr[idx]\n",
    "        img = Image.open(image_name)\n",
    "        img = img.convert(mode = 'RGB')\n",
    "        img_tensor = self.conv_to_tensor(img)\n",
    "        if not self.test:\n",
    "            image_labels = self.label_df[idx]\n",
    "            label_tensor = torch.zeros((1, output_dim))\n",
    "            image_labels = [int(x) for x in image_labels.split(',')]\n",
    "            for i, label in enumerate(image_labels):\n",
    "                label_tensor[0, i] = label\n",
    "            image_label = torch.tensor(label_tensor,dtype= torch.float32)\n",
    "            return (img_tensor,image_label.squeeze())\n",
    "        return (img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(labels_csv)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df,val_df = train_test_split(df, test_size=0.20)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "print(f\"Validation_Data Length: {len(val_df)}\\nTrain_Data Length: {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "train_dataset = ImageData(train_df,train_dir,data_transforms)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = ImageData(val_df,train_dir,data_transforms)\n",
    "val_loader = data.DataLoader(dataset=val_dataset,batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "dataloaders_dict = {'train':train_loader, 'val':val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(train_loader))\n",
    "print(f'Train Features: {features.shape}\\nTrain Labels: {labels.shape}')\n",
    "print()\n",
    "features, labels = next(iter(val_loader))\n",
    "print(f'Validation Features: {features.shape}\\nValidation Labels: {labels.shape}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_Data Length: 2222\n",
      " Train_Data Length: 8888\n"
     ]
    }
   ],
   "source": [
    "resnet_cls = models.resnet50()\n",
    "resnet_cls.load_state_dict(torch.load(resnet_weights_path))\n",
    "\n",
    "class AvgPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, x.shape[2:])\n",
    "    \n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self,num_outputs):\n",
    "        super(ResNet50,self).__init__()\n",
    "        self.resnet = resnet_cls\n",
    "        layer4 = self.resnet.layer4\n",
    "        self.resnet.layer4 = nn.Sequential(nn.Dropout(0.5), layer4)\n",
    "        self.resnet.avgpool = AvgPool()\n",
    "        self.resnet.fc = nn.Linear(2048, 1024)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1024, 256)\n",
    "        self.fc2 = nn.Linear(256, num_outputs)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "    \n",
    "        for param in self.bn2.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in self.resnet.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in self.fc1.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in self.bn1.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in self.fc2.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    def forward(self,x):\n",
    "        out = self.bn1(self.resnet(x))\n",
    "        out = self.bn2(F.relu(self.fc1(out)))\n",
    "        out = F.sigmoid(self.fc2(out))\n",
    "        return out\n",
    "    \n",
    "NeuralNet = ResNet50(num_outputs = output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in NeuralNet.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(p.numel() for p in NeuralNet.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features: torch.Size([50, 3, 224, 224])\n",
      "Train Labels: torch.Size([50, 932])\n",
      "\n",
      "Validation Features: torch.Size([50, 3, 224, 224])\n",
      "Validation Labels: torch.Size([50, 932])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING\")\n",
    "print(\"training examples: \",len(train_dataset))\n",
    "print(\"batch size: \",BATCH_SIZE)\n",
    "print(\"batches available: \",len(train_loader))\n",
    "print()\n",
    "print(\"VALIDATION\")\n",
    "print(\"validation examples: \",len(val_dataset))\n",
    "print(\"batch size: \",BATCH_SIZE)\n",
    "print(\"batches available: \",len(val_loader))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNet = NeuralNet.to(device)\n",
    "optimizer = optim.Adam(NeuralNet.parameters(),lr = LEARNING_RATE)\n",
    "loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience = 2)\n",
    "best_loss = np.inf\n",
    "best_f_score = np.inf\n",
    "best_precision = np.inf\n",
    "best_recall = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet50(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Dropout(p=0.5)\n",
       "      (1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool()\n",
       "    (fc): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=932, bias=True)\n",
       "  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec = []\n",
    "recall = []\n",
    "f = []\n",
    "losss = []\n",
    "val_f = []\n",
    "val_loss = []\n",
    "val_prec = []\n",
    "val_recall = []\n",
    "\n",
    "def store(phase,p,r,fs,l):\n",
    "    if phase == 'train':\n",
    "        prec.append(p)\n",
    "        recall.append(r)\n",
    "        f.append(fs)\n",
    "        losss.append(l)\n",
    "    else:\n",
    "        val_prec.append(p)\n",
    "        val_recall.append(r)\n",
    "        val_f.append(fs)\n",
    "        val_loss.append(l)\n",
    "        \n",
    "def calc(l,f,p,r,length):\n",
    "    loss = l/length\n",
    "    pre = p/length\n",
    "    fs = f/length\n",
    "    re = r/length\n",
    "    \n",
    "    return loss,fs,pre,re\n",
    "\n",
    "def result(epoch, NUM_EPOCHS,phase,epoch_loss,epoch_f_loss,epoch_precision,epoch_recall,elapsed_time):\n",
    "    print(\"\\tPhase: {}\\n\\t\\t Epoch: {}/{} | {}_loss:{:.8f} | f_score:{:.8f} | precision:{:.8f} | recall:{:.8f} | Time: {:.4f}s\".format(phase,\n",
    "                                                                              epoch+1,\n",
    "                                                                              NUM_EPOCHS,\n",
    "                                                                              phase,\n",
    "                                                                              epoch_loss,\n",
    "                                                                              epoch_f_score,\n",
    "                                                                              epoch_precision,\n",
    "                                                                              epoch_recall,\n",
    "                                                                              elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26,110,692 total parameters.\n",
      "17,567,396 training parameters.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    for phase in ['train', 'val']:\n",
    "        start_time = time.time()\n",
    "        if phase == 'train':\n",
    "            NeuralNet.train()\n",
    "        else:\n",
    "            NeuralNet.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_f_score = 0.0\n",
    "        running_precision = 0.0\n",
    "        running_recall = 0.0\n",
    "\n",
    "        for images_batch, labels_batch in tqdm(dataloaders_dict[phase],disable = DISABLE_TQDM):\n",
    "            images_batch = images_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                pred_batch = NeuralNet(images_batch)\n",
    "                _, preds = torch.max(pred_batch.data, 1)\n",
    "                loss = loss_func(pred_batch,labels_batch)\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            labels_cpu = labels_batch.cpu().detach().numpy()\n",
    "            pred_cpu = pred_batch.cpu().detach().numpy()\n",
    "\n",
    "#             print(metrics.multilabel_confusion_matrix(labels_cpu, pred_cpu>0.5, samplewise = True))\n",
    "\n",
    "            temp_precision, temp_recall, temp_f_score, _ = precision_recall_fscore_support(\n",
    "                                                                labels_cpu, pred_cpu > 0.1, beta=0.5, average='samples')\n",
    "\n",
    "            running_loss += loss.item() * images_batch.size(0)\n",
    "            running_precision += (temp_precision * len(images_batch))\n",
    "            running_recall += (temp_recall * len(images_batch))\n",
    "            running_f_score += (temp_f_score * len(images_batch))\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders_dict[phase].dataset)\n",
    "        epoch_f_score = running_f_score / len(dataloaders_dict[phase].dataset)\n",
    "        epoch_precision = running_precision / len(dataloaders_dict[phase].dataset)\n",
    "        epoch_recall = running_recall / len(dataloaders_dict[phase].dataset)\n",
    "        \n",
    "        store(phase,epoch_precision,epoch_recall,epoch_f_score,epoch_loss)\n",
    "\n",
    "        if phase == 'val' and epoch_f_score < best_f_score:\n",
    "#             print(\"model val_loss Improved from {:.8f} to {:.8f}\".format(best_loss,epoch_loss))\n",
    "            best_f_score = epoch_f_score\n",
    "            best_precision = epoch_precision\n",
    "            best_recall = epoch_recall\n",
    "            best_loss = epoch_loss\n",
    "            best_model_wts = copy.deepcopy(NeuralNet.state_dict())\n",
    "            torch.save(NeuralNet.state_dict(), weights_path)\n",
    "\n",
    "        if phase == 'val':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        elapsed_time = time.time()-start_time\n",
    "        result(epoch, NUM_EPOCHS,phase,epoch_loss,epoch_f_score,epoch_precision,epoch_recall,elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "training examples:  8888\n",
      "batch size:  50\n",
      "batches available:  178\n",
      "\n",
      "VALIDATION\n",
      "validation examples:  2222\n",
      "batch size:  50\n",
      "batches available:  45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resnet_cls = models.resnet50()\n",
    "resnet_cls.load_state_dict(torch.load(resnet_weights_path))\n",
    "\n",
    "class AvgPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, x.shape[2:])\n",
    "    \n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self,num_outputs):\n",
    "        super(ResNet50,self).__init__()\n",
    "        self.resnet = resnet_cls\n",
    "        layer4 = self.resnet.layer4\n",
    "        self.resnet.layer4 = nn.Sequential(nn.Dropout(0.5), layer4)\n",
    "        self.resnet.avgpool = AvgPool()\n",
    "        self.resnet.fc = nn.Linear(2048, 1024)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1024, 256)\n",
    "        self.fc2 = nn.Linear(256, num_outputs)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "    \n",
    "        for param in self.bn2.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in self.resnet.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in self.fc1.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in self.bn1.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in self.fc2.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    def forward(self,x):\n",
    "        out = self.bn1(self.resnet(x))\n",
    "        out = self.bn2(F.relu(self.fc1(out)))\n",
    "        out = F.sigmoid(self.fc2(out))\n",
    "        return out\n",
    "    \n",
    "NeuralNet = ResNet50(num_outputs = output_dim)\n",
    "NeuralNet.load_state_dict(torch.load(weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = torch.nn.Sequential(*(list(NeuralNet.children())[:-3]))\n",
    "print(newmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "acc = []\n",
    "\n",
    "for img_name in tqdm(os.listdir(train_dir)):\n",
    "    img = Image.open(train_dir + '/' + img_name)\n",
    "    img = img.convert(mode = 'RGB')\n",
    "    b = transforms.ToTensor()\n",
    "    img_tensor = b(img)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "    pred = newmodel(img_tensor)\n",
    "    temp = pred.detach().numpy()\n",
    "    features.append(temp)\n",
    "    acc.append(img_name.strip().split('_')[0])\n",
    "res_df = pd.DataFrame({'accession': acc,'features':features})\n",
    "\n",
    "res_df.to_pickle('best_features_{}_{}.pkl'.format(d, type_of_image))      #provide the path from where your multipred code will access the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y = [i for i in range(1, NUM_EPOCHS)]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, recall,label = 'train_recall')\n",
    "ax.plot(y, val_recall,'r',label='val_recall')\n",
    "plt.title('recall_{}_None'.format(d))\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('both_recall_{}_None.png'.format(d))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, recall,label = 'train_recall')\n",
    "plt.title('train_recall_{}_None'.format(d))\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('train_recall_{}_None.png'.format(d))\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, val_recall,'r',label='val_recall')\n",
    "plt.title('val_recall_{}_None'.format(d))\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('validation_recall_{}_None.png'.format(d))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPhase: train\n",
      "\t\t Epoch: 1/20 | train_loss:0.93893044 | f_score:0.05156340 | precision:0.04205003 | recall:0.99985554 | Time: 449.4322s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 1/20 | val_loss:0.89410764 | f_score:0.05088794 | precision:0.04148140 | recall:1.00000000 | Time: 126.2740s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 2/20 | train_loss:0.83552606 | f_score:0.06448353 | precision:0.05451973 | recall:0.94874575 | Time: 438.9258s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 2/20 | val_loss:0.77176658 | f_score:0.18679073 | precision:0.17248018 | recall:0.52176741 | Time: 201.2233s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 3/20 | train_loss:0.78037728 | f_score:0.19140890 | precision:0.20151631 | recall:0.58327598 | Time: 988.2677s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 3/20 | val_loss:0.74110300 | f_score:0.29630298 | precision:0.36361765 | recall:0.29232750 | Time: 111.9107s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 4/20 | train_loss:0.75449432 | f_score:0.27229700 | precision:0.33967494 | recall:0.37852795 | Time: 983.7621s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 4/20 | val_loss:0.72867415 | f_score:0.31761257 | precision:0.43300906 | recall:0.24616383 | Time: 133.7431s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 5/20 | train_loss:0.73890075 | f_score:0.31453344 | precision:0.45686758 | recall:0.25823675 | Time: 522.8291s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 5/20 | val_loss:0.74314513 | f_score:0.15310841 | precision:0.14479511 | recall:0.55332822 | Time: 132.8932s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 6/20 | train_loss:0.73457230 | f_score:0.32405583 | precision:0.47792769 | recall:0.24604238 | Time: 356.1329s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 6/20 | val_loss:0.70978641 | f_score:0.31731120 | precision:0.50843367 | recall:0.18932912 | Time: 78.1784s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 7/20 | train_loss:0.72326394 | f_score:0.32344964 | precision:0.50593833 | recall:0.21622171 | Time: 329.1233s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 7/20 | val_loss:0.71018917 | f_score:0.31750055 | precision:0.51047364 | recall:0.18737697 | Time: 79.2091s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 8/20 | train_loss:0.71468020 | f_score:0.31963071 | precision:0.52093860 | recall:0.19750096 | Time: 328.3193s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 8/20 | val_loss:0.69956156 | f_score:0.30611684 | precision:0.51617266 | recall:0.16152064 | Time: 78.4907s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 9/20 | train_loss:0.71153110 | f_score:0.31113267 | precision:0.52834599 | recall:0.18323232 | Time: 341.9352s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 9/20 | val_loss:0.70216897 | f_score:0.30576312 | precision:0.54852293 | recall:0.15340883 | Time: 83.7909s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 10/20 | train_loss:0.71052226 | f_score:0.30959619 | precision:0.55480802 | recall:0.17338109 | Time: 333.3824s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 10/20 | val_loss:0.70260273 | f_score:0.30456321 | precision:0.54463680 | recall:0.15925914 | Time: 83.2393s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 11/20 | train_loss:0.70993384 | f_score:0.30901303 | precision:0.55600921 | recall:0.17281479 | Time: 334.8887s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 11/20 | val_loss:0.70167569 | f_score:0.30650256 | precision:0.54796266 | recall:0.15525253 | Time: 83.2988s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 12/20 | train_loss:0.70790651 | f_score:0.31009067 | precision:0.55916746 | recall:0.16881175 | Time: 338.3290s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 12/20 | val_loss:0.70122930 | f_score:0.30608711 | precision:0.54809423 | recall:0.15504957 | Time: 82.6275s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 13/20 | train_loss:0.70786170 | f_score:0.30991822 | precision:0.55898787 | recall:0.16908528 | Time: 335.2374s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 13/20 | val_loss:0.70035195 | f_score:0.30598768 | precision:0.54813753 | recall:0.15391535 | Time: 82.7565s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 14/20 | train_loss:0.70747396 | f_score:0.31009085 | precision:0.55937071 | recall:0.16872385 | Time: 334.6398s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 14/20 | val_loss:0.70072145 | f_score:0.30619078 | precision:0.54798965 | recall:0.15473807 | Time: 86.9521s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 15/20 | train_loss:0.70706699 | f_score:0.31010743 | precision:0.55934073 | recall:0.16819485 | Time: 347.2952s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 15/20 | val_loss:0.70072989 | f_score:0.30604882 | precision:0.54785422 | recall:0.15465032 | Time: 80.9019s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 16/20 | train_loss:0.70703662 | f_score:0.30961834 | precision:0.55838244 | recall:0.16800060 | Time: 344.0407s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 16/20 | val_loss:0.70067487 | f_score:0.30605108 | precision:0.54773143 | recall:0.15476166 | Time: 86.4310s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 17/20 | train_loss:0.70697825 | f_score:0.30999721 | precision:0.55895583 | recall:0.16777688 | Time: 348.2487s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 17/20 | val_loss:0.70070146 | f_score:0.30616146 | precision:0.54807932 | recall:0.15470147 | Time: 87.7244s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 18/20 | train_loss:0.70708566 | f_score:0.30999465 | precision:0.55919706 | recall:0.16822814 | Time: 435.9195s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 18/20 | val_loss:0.70104079 | f_score:0.30606894 | precision:0.54752108 | recall:0.15498317 | Time: 84.0030s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 19/20 | train_loss:0.70723494 | f_score:0.30968121 | precision:0.55907500 | recall:0.16820318 | Time: 309.2751s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 19/20 | val_loss:0.70076899 | f_score:0.30600410 | precision:0.54788311 | recall:0.15490129 | Time: 73.2176s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 20/20 | train_loss:0.70750116 | f_score:0.30986293 | precision:0.55921182 | recall:0.16860292 | Time: 304.1281s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 20/20 | val_loss:0.70061472 | f_score:0.30604659 | precision:0.54800991 | recall:0.15460872 | Time: 79.3826s\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, prec, label = 'train_precision')\n",
    "ax.plot(y, val_prec, 'r',label = 'val_precision')\n",
    "plt.title('precision_{}_None'.format(d))\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('both_precision_{}_None.png'.format(d))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, prec, label = 'train_precision')\n",
    "plt.title('train_precision_{}_None'.format(d))\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('train_precision_{}_None.png'.format(d))\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, val_prec, 'r',label = 'val_precision')\n",
    "plt.title('val_precision_{}_None'.format(d))\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('validation_precision_{}_None.png'.format(d))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [i for i in range(1,21)]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, f,label = 'train_f_score')\n",
    "ax.plot(y, val_f, 'r',label = 'val_f_score')\n",
    "plt.title('f_score_{}_None'.format(d))\n",
    "plt.ylabel('F_score')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('both_f_score_{}_None.png'.format(d))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [i for i in range(1,21)]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, f,label = 'train_f_score')\n",
    "plt.title('train_f_score_{}_None'.format(d))\n",
    "plt.ylabel('F_score')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('train_f_score_{}_None.png'.format(d))\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, val_f, 'r',label = 'val_f_score')\n",
    "plt.title('val_fscore_{}_None'.format(d))\n",
    "plt.ylabel('F_score')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('validation_fscore_{}_None.png'.format(d))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [i for i in range(1,21)]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, losss, label = 'train_loss')\n",
    "ax.plot(y, val_loss, 'r', label = 'val_loss')\n",
    "plt.title('loss_{}_None'.format(d))\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('both_loss_{}_None.png'.format(d))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [i for i in range(1,21)]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, losss, label = 'train_loss')\n",
    "plt.title('train_loss_{}_None'.format(d))\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('train_loss_{}_None.png'.format(d))\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(y, val_loss, 'r',label = 'val_loss')\n",
    "plt.title('val_loss_{}_None'.format(d))\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('validation_loss_{}_None.png'.format(d))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
